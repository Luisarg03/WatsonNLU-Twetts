{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson-Natural Language Understanding\n",
    "\n",
    "### Ejemplo de implementacion de aplicacion Watson-Natural Language Understanding via api\n",
    "\n",
    "#### En este ejemplo se tratara de analizar los sentimientos contenidos dentro de twitts con respecto a xxx .\n",
    "#### Tambien se analizaran las emociones contenidas dentro de twitts con respecto a xxx .\n",
    "<br>\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Que es lo que analizamos ? [Segun Wikipedia](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_sentimiento)\n",
    "##### Basicamente, determinar la actitud de un interlocutor o usuario con respecto a algún tema o la polaridad (negativa o positiva) contextual general de un documento.\n",
    "<br>\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Librerias especiales implementadas\n",
    "<ul>\n",
    "<li><strong>tweepy</strong>, para captar twitts y facilitar la autenticacion via api</li>\n",
    "<li><strong>ibm_watson</strong>, para analisis de sentimientos/ emociones</li>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions, CategoriesOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Primera etapa: Obtener tweets\n",
    "<br>\n",
    "\n",
    "####  Authentication en la api de twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = '-'\n",
    "consumerSecret = '-'\n",
    "accessToken = '-'\n",
    "accessTokenSecret = '-'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Un poco de referencia del metodo que se utilizara para buscar twitts de los temas.\n",
    "#####  [tweepy.API().search()](https://docs.tweepy.org/en/latest/api.html?highlight=tweepy.API#API.search)\n",
    "\n",
    "##### (Metodo premium)\n",
    "##### [API.search_30_day()](https://docs.tweepy.org/en/latest/api.html?highlight=API.search_30_day#API.search_30_day)\n",
    "<br>\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "#### Se inicia una lista vacia que se llenara con los twitts que contengan las palabras que le indiquemos al buscador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tweets = []\n",
    "\n",
    "### Primer tema de busqueda\n",
    "search_tweets = api.search('covid', lang=\"es\", count=100, tweet_mode='extended')\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    if 'retweeted_status' in tweet._json:\n",
    "        list_tweets.append(tweet._json['retweeted_status']['full_text'].upper())\n",
    "        # print(tweet._json['retweeted_status']['full_text'])\n",
    "    else:\n",
    "        list_tweets.append(tweet.full_text.upper())\n",
    "        # print(tweet.full_text)\n",
    "\n",
    "### Quitamos los tweets spam.\n",
    "list_tweets = list(set(list_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--------------------------------------------------\n",
    "#### Seccion para visualizar que obtuvimos.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "print(len(list_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BELTRANDELRIO SOBRE LA INFORMACIÓN QUE DIO @RODPAC DE QUE LAS PERSONAS QUE VIAJEN A MÉXICO DESDE UK DEBERÁN A SU REGRESO HACER UNA CUARENTENA EN UN HOTEL, TE COMENTO QUE MÉXICO NO ESTÁ INCLUIDO EN LA LISTA QUE PUBLICÓ EL GOBIERNO DE UK, SALUDOS.\n",
      "\n",
      "HTTPS://T.CO/TZ9OVTSRGX \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list_tweets:\n",
    "    print(i, '\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Segunda etapa: Analizis con Watson\n",
    "\n",
    "<br>\n",
    "\n",
    "###  Autenticacion en la api de IBM-Watson.\n",
    "#### [documentacion](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('-')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2020-08-01',\n",
    "    authenticator=authenticator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de endpoint\n",
    "#### [documentacion](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#service-endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = '-'\n",
    "natural_language_understanding.set_service_url(service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Metodo para analizar el sentimiento de los textos.\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#sentiment\n",
    "\n",
    "#### Metodo para clasificar los textos.\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#categories\n",
    "\n",
    "### Doc\n",
    "[natural_language_understanding()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html)\n",
    "\n",
    "[analyse()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=analyze#ibm_watson.natural_language_understanding_v1.NaturalLanguageUnderstandingV1.analyze)\n",
    "\n",
    "[Features()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=features#ibm_watson.natural_language_understanding_v1.Features)\n",
    "\n",
    "[SentimentOptions()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=sentimentoptions#ibm_watson.natural_language_understanding_v1.SentimentOptions)\n",
    "\n",
    "[CategoriesOptions()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=ategoriesoptions#ibm_watson.natural_language_understanding_v1.CategoriesOptions)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Un ejemplo de como funciona este metodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 1,\n",
      "    \"text_characters\": 31,\n",
      "    \"features\": 1\n",
      "  },\n",
      "  \"sentiment\": {\n",
      "    \"targets\": [\n",
      "      {\n",
      "        \"text\": \"naranjas\",\n",
      "        \"score\": -0.888776,\n",
      "        \"label\": \"negative\"\n",
      "      }\n",
      "    ],\n",
      "    \"document\": {\n",
      "      \"score\": -0.888776,\n",
      "      \"label\": \"negative\"\n",
      "    }\n",
      "  },\n",
      "  \"language\": \"es\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = natural_language_understanding.analyze(\n",
    "                                                language='es',\n",
    "                                                text='las naranjas son amargas y feas',\n",
    "                                                features=Features(\n",
    "                                                                sentiment=SentimentOptions(targets=['manzanas', 'naranjas'])\n",
    "                                                                # ,categories=CategoriesOptions(limit=3)\n",
    "                                                    )\n",
    "                                                )\n",
    "\n",
    "\n",
    "print(json.dumps(response.get_result(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Para entender cada campo del response que obtenemos -> [Doc Response](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#analyze)\n",
    "\n",
    "<br>\n",
    "\n",
    "-----------------------\n",
    "<br>\n",
    "\n",
    "####  Scoring y clasificasión de tweets\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for tweet in list_tweets:\n",
    "    response = natural_language_understanding.analyze(\n",
    "                                                language='es',\n",
    "                                                text=tweet,\n",
    "                                                features=Features(\n",
    "                                                                sentiment=SentimentOptions(targets=[tweet])\n",
    "                                                    )\n",
    "                                                )\n",
    "\n",
    "\n",
    "    json_df = response.get_result()\n",
    "    json_parse = json_df[\"sentiment\"][\"targets\"][0]\n",
    "    data.append(json_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BELTRANDELRIO SOBRE LA INFORMACIÓN QUE DIO @R...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL HOSPITAL REGIONAL MARIA AUXILIADORA  INFORM...</td>\n",
       "      <td>-0.566191</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POR REBROTE DEL COVID, PIB CAERÁ 1% A MARZO\\n ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¿TIENES O TUVISTE COVID - 19? UPAEP TE INVITA ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#CHIMALHUACÁN SIGUE EN PIE DE LUCHA ANTE EL CO...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     score     label mixed\n",
       "0  @BELTRANDELRIO SOBRE LA INFORMACIÓN QUE DIO @R...  0.000000   neutral   NaN\n",
       "1  EL HOSPITAL REGIONAL MARIA AUXILIADORA  INFORM... -0.566191  negative   NaN\n",
       "2  POR REBROTE DEL COVID, PIB CAERÁ 1% A MARZO\\n ...  0.000000   neutral   NaN\n",
       "3  ¿TIENES O TUVISTE COVID - 19? UPAEP TE INVITA ...  0.000000   neutral   NaN\n",
       "4  #CHIMALHUACÁN SIGUE EN PIE DE LUCHA ANTE EL CO...  0.000000   neutral   NaN"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTO: LO VEN??\n",
      "O NO LO QUIEREN VER??\n",
      "YA DIÓ NEGATIVO EN LA PRUEBA DE COVID..\n",
      "\n",
      "LOS FANÁTICOS Y LOS BOTS PAGADOS DIRÁN QUE ES UN MILAGRO..\n",
      "DIRÁN QUE SU \"FUERZA MORAL\" LO PROTEGE..\n",
      "DIRÁN QUE ES EL MESÍAS..\n",
      "\n",
      "NOSOTRAS, SABEMOS LA VERDAD..\n",
      "\n",
      "TODO FUE UNA MENTIRA!!.\n",
      "\n",
      "#VIEJOMENTIROSO \n",
      "\n",
      "PUNTUACIÓN: 0.27392 \n",
      "\n",
      "ETIQUETA: positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 13\n",
    "print('TEXTO:', df['text'].iloc[index], '\\n')\n",
    "print('PUNTUACIÓN:', df['score'].iloc[index], '\\n')\n",
    "print('ETIQUETA:', df['label'].iloc[index], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
