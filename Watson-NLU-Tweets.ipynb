{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson-Natural Language Understanding\n",
    "\n",
    "--------------------------------\n",
    "<br>\n",
    "\n",
    "### Descarga la presentación en [GitHub](https://github.com/Luisarg03/WatsonNLU-Twetts)\n",
    "<br>\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "### Ejemplo de implementación de aplicación Watson-Natural Language Understanding via api\n",
    "\n",
    "#### En este ejemplo se tratara de analizar los sentimientos contenidos dentro de twitts con respecto a xxx .\n",
    "#### También se analizaran las emociones contenidas dentro de twitts con respecto a xxx .\n",
    "<br>\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Que es lo que analizamos ? [Segun Wikipedia](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_sentimiento)\n",
    "##### Básicamente, determinar la actitud de un interlocutor o usuario con respecto a algún tema o la polaridad (negativa o positiva) contextual general de un documento.\n",
    "<br>\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Librerías especiales implementadas\n",
    "<ul>\n",
    "<li><strong>tweepy</strong>, para captar twitts y facilitar la autenticación via api</li>\n",
    "<li><strong>ibm_watson</strong>, para analisis de sentimientos/ emociones</li>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions, CategoriesOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Primera etapa: Obtener tweets\n",
    "<br>\n",
    "\n",
    "####  Autenticación en la api de twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = '-'\n",
    "consumerSecret = '-'\n",
    "accessToken = '-'\n",
    "accessTokenSecret = '-'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Un poco de referencia del método que se utilizara para buscar twitts de los temas.\n",
    "#####  [tweepy.API().search()](https://docs.tweepy.org/en/latest/api.html?highlight=tweepy.API#API.search)\n",
    "\n",
    "##### (Metodo premium)\n",
    "##### [API.search_30_day()](https://docs.tweepy.org/en/latest/api.html?highlight=API.search_30_day#API.search_30_day)\n",
    "<br>\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "#### Se inicia una lista vacía que se llenara con los twitts que contengan las palabras que le indiquemos al buscador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tweets = []\n",
    "\n",
    "### Primer tema de busqueda\n",
    "search_tweets = api.search('covid', lang=\"es\", count=100, tweet_mode='extended')\n",
    "\n",
    "for tweet in search_tweets:\n",
    "    if 'retweeted_status' in tweet._json:\n",
    "        list_tweets.append(tweet._json['retweeted_status']['full_text'].upper())\n",
    "        # print(tweet._json['retweeted_status']['full_text'])\n",
    "    else:\n",
    "        list_tweets.append(tweet.full_text.upper())\n",
    "        # print(tweet.full_text)\n",
    "\n",
    "### Quitamos los tweets spam.\n",
    "list_tweets = list(set(list_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--------------------------------------------------\n",
    "#### Vistazo a la lista que obtuvimos.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "print(len(list_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESPUÉS DE MUCHO IR Y VENIR CON UNA GRAN CANTIDAD DE (DES)INFORMACIÓN SOBRE EL USO, SEGURIDAD Y UTILIDAD DE IVERMECTINA PARA TRATAR COVID-19, AYER LA PROPIA FARMACÉUTICA @MERCK, FABRICANTE DEL MEDICAMENTO, PUBLICÓ ESTE COMUNICADO ADVIRTIENDO QUE: 🧵👇🏼 HTTPS://T.CO/JLPWYAEY59 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list_tweets:\n",
    "    print(i, '\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Segunda etapa: Análisis con Watson\n",
    "\n",
    "<br>\n",
    "\n",
    "###  Autenticación en la api de IBM-Watson.\n",
    "#### [documentacion](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('-')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2020-08-01',\n",
    "    authenticator=authenticator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de endpoint\n",
    "#### [documentacion](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#service-endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = '-'\n",
    "natural_language_understanding.set_service_url(service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Método para analizar el sentimiento de los textos.\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#sentiment\n",
    "\n",
    "#### Método para clasificar los textos.\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#categories\n",
    "\n",
    "### Doc\n",
    "[natural_language_understanding()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html)\n",
    "\n",
    "[analyse()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=analyze#ibm_watson.natural_language_understanding_v1.NaturalLanguageUnderstandingV1.analyze)\n",
    "\n",
    "[Features()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=features#ibm_watson.natural_language_understanding_v1.Features)\n",
    "\n",
    "[SentimentOptions()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=sentimentoptions#ibm_watson.natural_language_understanding_v1.SentimentOptions)\n",
    "\n",
    "[CategoriesOptions()](http://watson-developer-cloud.github.io/python-sdk/v3.0.2/apis/ibm_watson.natural_language_understanding_v1.html?highlight=ategoriesoptions#ibm_watson.natural_language_understanding_v1.CategoriesOptions)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Un ejemplo de como funciona este método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 1,\n",
      "    \"text_characters\": 31,\n",
      "    \"features\": 1\n",
      "  },\n",
      "  \"sentiment\": {\n",
      "    \"targets\": [\n",
      "      {\n",
      "        \"text\": \"naranjas\",\n",
      "        \"score\": -0.888776,\n",
      "        \"label\": \"negative\"\n",
      "      }\n",
      "    ],\n",
      "    \"document\": {\n",
      "      \"score\": -0.888776,\n",
      "      \"label\": \"negative\"\n",
      "    }\n",
      "  },\n",
      "  \"language\": \"es\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = natural_language_understanding.analyze(\n",
    "                                                language='es',\n",
    "                                                text='las naranjas son amargas y feas',\n",
    "                                                features=Features(\n",
    "                                                                sentiment=SentimentOptions(targets=['manzanas', 'naranjas'])\n",
    "                                                                # ,categories=CategoriesOptions(limit=3)\n",
    "                                                    )\n",
    "                                                )\n",
    "\n",
    "\n",
    "print(json.dumps(response.get_result(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Para entender cada campo del response que obtenemos -> [Doc Response](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#analyze)\n",
    "\n",
    "<br>\n",
    "\n",
    "-----------------------\n",
    "<br>\n",
    "\n",
    "####  Scoring y clasificasión de tweets\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for tweet in list_tweets:\n",
    "    response = natural_language_understanding.analyze(\n",
    "                                                language='es',\n",
    "                                                text=tweet,\n",
    "                                                features=Features(\n",
    "                                                                sentiment=SentimentOptions(targets=[tweet])\n",
    "                                                    )\n",
    "                                                )\n",
    "\n",
    "\n",
    "    json_df = response.get_result()\n",
    "    json_parse = json_df[\"sentiment\"][\"targets\"][0]\n",
    "    data.append(json_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DESPUÉS DE MUCHO IR Y VENIR CON UNA GRAN CANTI...</td>\n",
       "      <td>0.911741</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL MUNICIPIO DE IXTAPALUCA ES MODELO DE ACCIÓN...</td>\n",
       "      <td>-0.530367</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#GRACIASPORTULUCHA EL GOBIERNO DE \\n@JTOLENTIN...</td>\n",
       "      <td>-0.732547</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#GRACIASPORTULUCHA\\nLAS ACCIONES IMPLEMENTADAS...</td>\n",
       "      <td>0.545318</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#CHIMALHUACÁN SIGUE EN PIE DE LUCHA ANTE EL CO...</td>\n",
       "      <td>-0.454461</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     score     label mixed\n",
       "0  DESPUÉS DE MUCHO IR Y VENIR CON UNA GRAN CANTI...  0.911741  positive   NaN\n",
       "1  EL MUNICIPIO DE IXTAPALUCA ES MODELO DE ACCIÓN... -0.530367  negative   NaN\n",
       "2  #GRACIASPORTULUCHA EL GOBIERNO DE \\n@JTOLENTIN... -0.732547  negative   NaN\n",
       "3  #GRACIASPORTULUCHA\\nLAS ACCIONES IMPLEMENTADAS...  0.545318  positive   NaN\n",
       "4  #CHIMALHUACÁN SIGUE EN PIE DE LUCHA ANTE EL CO... -0.454461  negative   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTO: PARIS ES UN IRRESPONSABLE, DICE Q LOS ESTUDIANTES NO SON CAPACES DE TRANSMITIR EL COVID. SIN EMBARGO, LA EVIDENCIA CIENTÍFICA SEÑALA Q NIÑOS Y JOVENES CONTRAEN Y PROPAGAN EL VIRUS SIN MOSTRAR SÍNTOMAS. POR ESTA RAZÓN, LOS ESCOLARES SON LOS QUE MÁS CONTAGIAN DENTRO DE LOS HOGARES. \n",
      "\n",
      "PUNTUACIÓN: -0.412403 \n",
      "\n",
      "ETIQUETA: negative \n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 13\n",
    "print('TEXTO:', df['text'].iloc[index], '\\n')\n",
    "print('PUNTUACIÓN:', df['score'].iloc[index], '\\n')\n",
    "print('ETIQUETA:', df['label'].iloc[index], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
